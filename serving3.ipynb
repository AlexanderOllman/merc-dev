{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9b5a2f6",
   "metadata": {},
   "source": [
    "# RRREEEEEEEEEEE\n",
    "\n",
    "This notebook retrieves the latest run artifact for the model **blip2_feature_extractor** from MLflow, loads the corresponding fine-tuned checkpoint, converts it to a TorchScript model, registers (or updates) an MLflow Model called **blip_ft_production**, and generates a KServe InferenceService YAML for serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "354cfc63-c05a-4f67-b479-fc076bb5555f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.11/site-packages (1.35.40)\n",
      "Requirement already satisfied: mlflow in /opt/conda/lib/python3.11/site-packages (2.16.0)\n",
      "Collecting salesforce-lavis\n",
      "  Using cached salesforce_lavis-1.0.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n",
      "  Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch)\n",
      "  Using cached triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.40 in /opt/conda/lib/python3.11/site-packages (from boto3) (1.35.55)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.11/site-packages (from boto3) (0.10.3)\n",
      "Requirement already satisfied: mlflow-skinny==2.16.0 in /opt/conda/lib/python3.11/site-packages (from mlflow) (2.16.0)\n",
      "Requirement already satisfied: Flask<4 in /opt/conda/lib/python3.11/site-packages (from mlflow) (3.0.3)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /opt/conda/lib/python3.11/site-packages (from mlflow) (1.14.0)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /opt/conda/lib/python3.11/site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /opt/conda/lib/python3.11/site-packages (from mlflow) (3.4.1)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /opt/conda/lib/python3.11/site-packages (from mlflow) (3.7)\n",
      "Requirement already satisfied: matplotlib<4 in /opt/conda/lib/python3.11/site-packages (from mlflow) (3.8.4)\n",
      "Requirement already satisfied: numpy<3 in /opt/conda/lib/python3.11/site-packages (from mlflow) (1.26.4)\n",
      "Requirement already satisfied: pandas<3 in /opt/conda/lib/python3.11/site-packages (from mlflow) (2.1.4)\n",
      "Requirement already satisfied: pyarrow<18,>=4.0.0 in /opt/conda/lib/python3.11/site-packages (from mlflow) (11.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in /opt/conda/lib/python3.11/site-packages (from mlflow) (1.3.2)\n",
      "Requirement already satisfied: scipy<2 in /opt/conda/lib/python3.11/site-packages (from mlflow) (1.11.3)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from mlflow) (2.0.30)\n",
      "Requirement already satisfied: gunicorn<24 in /opt/conda/lib/python3.11/site-packages (from mlflow) (23.0.0)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.16.0->mlflow) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.16.0->mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.16.0->mlflow) (2.2.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.16.0->mlflow) (0.36.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.16.0->mlflow) (3.1.43)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.16.0->mlflow) (8.5.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.16.0->mlflow) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.16.0->mlflow) (1.30.0)\n",
      "Requirement already satisfied: packaging<25 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.16.0->mlflow) (24.1)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.16.0->mlflow) (4.25.5)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.16.0->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.16.0->mlflow) (2.32.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from mlflow-skinny==2.16.0->mlflow) (0.5.1)\n",
      "Collecting contexttimer (from salesforce-lavis)\n",
      "  Using cached contexttimer-0.3.3-py3-none-any.whl\n",
      "Collecting decord (from salesforce-lavis)\n",
      "  Using cached decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\n",
      "Collecting einops>=0.4.1 (from salesforce-lavis)\n",
      "  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting fairscale==0.4.4 (from salesforce-lavis)\n",
      "  Using cached fairscale-0.4.4-py3-none-any.whl\n",
      "Collecting ftfy (from salesforce-lavis)\n",
      "  Using cached ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting iopath (from salesforce-lavis)\n",
      "  Using cached iopath-0.1.10-py3-none-any.whl\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.11/site-packages (from salesforce-lavis) (8.22.2)\n",
      "Collecting omegaconf (from salesforce-lavis)\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting opencv-python-headless==4.5.5.64 (from salesforce-lavis)\n",
      "  Using cached opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting opendatasets (from salesforce-lavis)\n",
      "  Using cached opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting plotly (from salesforce-lavis)\n",
      "  Using cached plotly-6.0.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pre-commit (from salesforce-lavis)\n",
      "  Using cached pre_commit-4.1.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting pycocoevalcap (from salesforce-lavis)\n",
      "  Using cached pycocoevalcap-1.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pycocotools (from salesforce-lavis)\n",
      "  Using cached pycocotools-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting python-magic (from salesforce-lavis)\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.11/site-packages (from salesforce-lavis) (0.22.0)\n",
      "Collecting sentencepiece (from salesforce-lavis)\n",
      "  Using cached sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting spacy (from salesforce-lavis)\n",
      "  Using cached spacy-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
      "Collecting streamlit (from salesforce-lavis)\n",
      "  Using cached streamlit-1.43.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting timm==0.4.12 (from salesforce-lavis)\n",
      "  Using cached timm-0.4.12-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting torchvision (from salesforce-lavis)\n",
      "  Using cached torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from salesforce-lavis) (4.66.6)\n",
      "Collecting transformers<4.27,>=4.25.0 (from salesforce-lavis)\n",
      "  Using cached transformers-4.26.1-py3-none-any.whl.metadata (100 kB)\n",
      "Collecting webdataset (from salesforce-lavis)\n",
      "  Using cached webdataset-0.2.111-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.11/site-packages (from salesforce-lavis) (0.44.0)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from botocore<1.36.0,>=1.35.40->boto3) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.11/site-packages (from botocore<1.36.0,>=1.35.40->boto3) (1.26.20)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from Flask<4->mlflow) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.11/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.11/site-packages (from Flask<4->mlflow) (1.8.2)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /opt/conda/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.5)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /opt/conda/lib/python3.11/site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0 (from transformers<4.27,>=4.25.0->salesforce-lavis)\n",
      "  Downloading huggingface_hub-0.29.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<4.27,>=4.25.0->salesforce-lavis)\n",
      "  Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<4.27,>=4.25.0->salesforce-lavis)\n",
      "  Using cached tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from ftfy->salesforce-lavis) (0.2.13)\n",
      "Collecting portalocker (from iopath->salesforce-lavis)\n",
      "  Using cached portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython->salesforce-lavis) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython->salesforce-lavis) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.11/site-packages (from ipython->salesforce-lavis) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.11/site-packages (from ipython->salesforce-lavis) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython->salesforce-lavis) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython->salesforce-lavis) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/conda/lib/python3.11/site-packages (from ipython->salesforce-lavis) (5.14.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython->salesforce-lavis) (4.9.0)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->salesforce-lavis)\n",
      "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
      "Collecting kaggle (from opendatasets->salesforce-lavis)\n",
      "  Using cached kaggle-1.6.17-py3-none-any.whl\n",
      "Collecting narwhals>=1.15.1 (from plotly->salesforce-lavis)\n",
      "  Using cached narwhals-1.29.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting cfgv>=2.0.0 (from pre-commit->salesforce-lavis)\n",
      "  Using cached cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting identify>=1.0.0 (from pre-commit->salesforce-lavis)\n",
      "  Using cached identify-2.6.8-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting nodeenv>=0.11.1 (from pre-commit->salesforce-lavis)\n",
      "  Using cached nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting virtualenv>=20.10.0 (from pre-commit->salesforce-lavis)\n",
      "  Using cached virtualenv-20.29.2-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.11/site-packages (from scikit-image->salesforce-lavis) (2.36.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.11/site-packages (from scikit-image->salesforce-lavis) (2024.9.20)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.11/site-packages (from scikit-image->salesforce-lavis) (0.4)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy->salesforce-lavis)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy->salesforce-lavis)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy->salesforce-lavis)\n",
      "  Using cached murmurhash-1.0.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy->salesforce-lavis)\n",
      "  Using cached cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy->salesforce-lavis)\n",
      "  Using cached preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy->salesforce-lavis)\n",
      "  Using cached thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy->salesforce-lavis)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy->salesforce-lavis)\n",
      "  Using cached srsly-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy->salesforce-lavis)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy->salesforce-lavis)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy->salesforce-lavis)\n",
      "  Using cached typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.11/site-packages (from spacy->salesforce-lavis) (2.9.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from spacy->salesforce-lavis) (75.3.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy->salesforce-lavis)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /opt/conda/lib/python3.11/site-packages (from streamlit->salesforce-lavis) (5.4.1)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /opt/conda/lib/python3.11/site-packages (from streamlit->salesforce-lavis) (8.5.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /opt/conda/lib/python3.11/site-packages (from streamlit->salesforce-lavis) (0.10.2)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit->salesforce-lavis)\n",
      "  Using cached watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit->salesforce-lavis)\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.11/site-packages (from streamlit->salesforce-lavis) (6.4.1)\n",
      "Collecting braceexpand (from webdataset->salesforce-lavis)\n",
      "  Using cached braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit->salesforce-lavis) (4.23.0)\n",
      "Requirement already satisfied: google-auth~=2.0 in /opt/conda/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.0->mlflow) (2.36.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.16.0->mlflow) (4.0.11)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.16.0->mlflow) (3.20.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython->salesforce-lavis) (0.8.4)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy->salesforce-lavis)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.11/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.16.0->mlflow) (1.2.14)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /opt/conda/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.16.0->mlflow) (0.51b0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython->salesforce-lavis) (0.7.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->salesforce-lavis) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->salesforce-lavis) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.40->boto3) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.16.0->mlflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.16.0->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.16.0->mlflow) (2024.8.30)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy->salesforce-lavis)\n",
      "  Using cached blis-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy->salesforce-lavis)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy->salesforce-lavis)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy->salesforce-lavis) (13.9.4)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->salesforce-lavis)\n",
      "  Using cached distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in /opt/conda/lib/python3.11/site-packages (from virtualenv>=20.10.0->pre-commit->salesforce-lavis) (4.3.6)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy->salesforce-lavis)\n",
      "  Using cached cloudpathlib-0.21.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy->salesforce-lavis)\n",
      "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting python-slugify (from kaggle->opendatasets->salesforce-lavis)\n",
      "  Using cached python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.11/site-packages (from kaggle->opendatasets->salesforce-lavis) (6.2.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython->salesforce-lavis) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython->salesforce-lavis) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython->salesforce-lavis) (0.2.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.16.0->mlflow) (1.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.16.0->mlflow) (5.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.0->mlflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.0->mlflow) (4.9)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->salesforce-lavis) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->salesforce-lavis) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->salesforce-lavis) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->salesforce-lavis) (0.21.0)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->salesforce-lavis)\n",
      "  Using cached marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->salesforce-lavis) (3.0.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.11/site-packages (from bleach->kaggle->opendatasets->salesforce-lavis) (0.5.1)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle->opendatasets->salesforce-lavis)\n",
      "  Using cached text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->salesforce-lavis) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.0->mlflow) (0.6.1)\n",
      "Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
      "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
      "Using cached salesforce_lavis-1.0.2-py3-none-any.whl (1.8 MB)\n",
      "Using cached opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
      "Using cached timm-0.4.12-py3-none-any.whl (376 kB)\n",
      "Using cached einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Using cached transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "Using cached decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
      "Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Using cached ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Using cached opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
      "Using cached plotly-6.0.0-py3-none-any.whl (14.8 MB)\n",
      "Using cached pre_commit-4.1.0-py2.py3-none-any.whl (220 kB)\n",
      "Using cached pycocoevalcap-1.2-py3-none-any.whl (104.3 MB)\n",
      "Using cached pycocotools-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (458 kB)\n",
      "Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Using cached sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached spacy-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.6 MB)\n",
      "Using cached streamlit-1.43.0-py2.py3-none-any.whl (9.7 MB)\n",
      "Using cached torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
      "Using cached webdataset-0.2.111-py3-none-any.whl (85 kB)\n",
      "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Using cached cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
      "Using cached cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (218 kB)\n",
      "Downloading huggingface_hub-0.29.2-py3-none-any.whl (468 kB)\n",
      "Using cached identify-2.6.8-py2.py3-none-any.whl (99 kB)\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Using cached murmurhash-1.0.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (134 kB)\n",
      "Using cached narwhals-1.29.0-py3-none-any.whl (305 kB)\n",
      "Using cached nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
      "Using cached preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
      "Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Using cached srsly-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Using cached thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
      "Using cached tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Using cached typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Using cached virtualenv-20.29.2-py3-none-any.whl (4.3 MB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Using cached braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
      "Using cached portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
      "Using cached blis-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "Using cached cloudpathlib-0.21.0-py3-none-any.whl (52 kB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Using cached python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Using cached marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Installing collected packages: triton, tokenizers, text-unidecode, sentencepiece, nvidia-cusparselt-cu12, distlib, cymem, contexttimer, braceexpand, antlr4-python3-runtime, webdataset, watchdog, wasabi, sympy, spacy-loggers, spacy-legacy, smart-open, shellingham, regex, python-slugify, python-magic, portalocker, opencv-python-headless, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nodeenv, narwhals, murmurhash, marisa-trie, identify, ftfy, filelock, einops, decord, cloudpathlib, cfgv, catalogue, blis, virtualenv, srsly, pydeck, preshed, plotly, nvidia-cusparse-cu12, nvidia-cudnn-cu12, language-data, kaggle, iopath, huggingface-hub, typer, transformers, pycocotools, pre-commit, opendatasets, nvidia-cusolver-cu12, langcodes, confection, weasel, torch, thinc, pycocoevalcap, torchvision, streamlit, spacy, fairscale, timm, salesforce-lavis\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "  Attempting uninstall: narwhals\n",
      "    Found existing installation: narwhals 1.13.2\n",
      "    Uninstalling narwhals-1.13.2:\n",
      "      Successfully uninstalled narwhals-1.13.2\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 blis-1.2.0 braceexpand-0.1.7 catalogue-2.0.10 cfgv-3.4.0 cloudpathlib-0.21.0 confection-0.1.5 contexttimer-0.3.3 cymem-2.0.11 decord-0.6.0 distlib-0.3.9 einops-0.8.1 fairscale-0.4.4 filelock-3.17.0 ftfy-6.3.1 huggingface-hub-0.29.2 identify-2.6.8 iopath-0.1.10 kaggle-1.6.17 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.12 narwhals-1.29.0 nodeenv-1.9.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 omegaconf-2.3.0 opencv-python-headless-4.5.5.64 opendatasets-0.1.22 plotly-6.0.0 portalocker-3.1.1 pre-commit-4.1.0 preshed-3.0.9 pycocoevalcap-1.2 pycocotools-2.0.8 pydeck-0.9.1 python-magic-0.4.27 python-slugify-8.0.4 regex-2024.11.6 salesforce-lavis-1.0.2 sentencepiece-0.2.0 shellingham-1.5.4 smart-open-7.1.0 spacy-3.8.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 streamlit-1.43.0 sympy-1.13.1 text-unidecode-1.3 thinc-8.3.4 timm-0.4.12 tokenizers-0.13.3 torch-2.6.0 torchvision-0.21.0 transformers-4.26.1 triton-3.2.0 typer-0.15.2 virtualenv-20.29.2 wasabi-1.1.3 watchdog-6.0.0 weasel-0.4.1 webdataset-0.2.111\n"
     ]
    }
   ],
   "source": [
    "!pip install torch boto3 mlflow salesforce-lavis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f833cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/fairscale/experimental/nn/offload.py:19: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  return torch.cuda.amp.custom_fwd(orig_func)  # type: ignore\n",
      "/opt/conda/lib/python3.11/site-packages/fairscale/experimental/nn/offload.py:30: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  return torch.cuda.amp.custom_bwd(orig_func)  # type: ignore\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import torch\n",
    "from lavis.models import load_model_and_preprocess\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# --- Training and S3 configuration (for reference) ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"blip2_feature_extractor\"\n",
    "model_type = \"pretrain\"  # as used during training\n",
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "lr = 1e-5\n",
    "save_model_path = \"blip2_finetuned_v2.pt\"\n",
    "\n",
    "# No explicit S3 paths needed here because we retrieve the artifact via MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b3e90",
   "metadata": {},
   "source": [
    "## Step 1: Retrieve the Latest Run Artifact from MLflow\n",
    "\n",
    "We assume the MLflow experiment is named **blip2_feature_extractor**. The checkpoint artifact is stored at `model_epoch_1/data/model.pth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf243a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest run ID: 59dacdf4959f46bdb4fc0fc65596a8a5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d990882a3a7544159864f782db0837f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded model checkpoint to: /tmp/tmp84vs_70_/model_epoch_9/data/model.pth\n"
     ]
    }
   ],
   "source": [
    "client = MlflowClient()\n",
    "experiment_name = \"BLIP 2 F1 finetuning\"\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "    raise Exception(f\"Experiment {experiment_name} not found.\")\n",
    "\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "# Search for the most recent run in the experiment\n",
    "runs = client.search_runs(experiment_ids=[experiment_id], order_by=[\"start_time DESC\"], max_results=1)\n",
    "if not runs:\n",
    "    raise Exception(\"No runs found in the experiment.\")\n",
    "\n",
    "latest_run = runs[0]\n",
    "print(\"Latest run ID:\", latest_run.info.run_id)\n",
    "\n",
    "# Assume the checkpoint artifact is stored under this relative path\n",
    "artifact_path = \"model_epoch_9/data/model.pth\"\n",
    "\n",
    "# Download the artifact locally\n",
    "local_checkpoint_path = mlflow.artifacts.download_artifacts(\n",
    "    run_id=latest_run.info.run_id, artifact_path=artifact_path\n",
    ")\n",
    "print(\"Downloaded model checkpoint to:\", local_checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87b4aee",
   "metadata": {},
   "source": [
    "## Step 2: Load the Base Model and the Fine-Tuned Checkpoint\n",
    "\n",
    "We use Lavisâ€™s helper to load the base model and then load the fine-tuned weights from the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78087fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "freeze vision encoder\n",
      "load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded fine-tuned weights into the base model.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"blip2_feature_extractor\"\n",
    "model_type = \"pretrain\"  # as used during training\n",
    "\n",
    "# Load the base model and preprocessors\n",
    "base_model, vis_processors, txt_processors = load_model_and_preprocess(model_name, model_type=model_type, is_eval=False)\n",
    "base_model = base_model.to(device)\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(local_checkpoint_path, map_location=device, weights_only=False)\n",
    "\n",
    "if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\n",
    "    state_dict = checkpoint['state_dict']\n",
    "elif hasattr(checkpoint, 'state_dict'):\n",
    "    # If the checkpoint is a model instance, extract its state dict.\n",
    "    state_dict = checkpoint.state_dict()\n",
    "else:\n",
    "    state_dict = checkpoint\n",
    "\n",
    "# Load the fine-tuned weights into the base model\n",
    "base_model.load_state_dict(state_dict)\n",
    "print(\"Loaded fine-tuned weights into the base model.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9455c16c",
   "metadata": {},
   "source": [
    "## Step 3: Convert the Fine-Tuned Model to TorchScript\n",
    "\n",
    "We attempt to script the model. If that fails, we fall back to tracing using a dummy input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9d4c2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributed process group not initialized; monkey-patching dist.get_rank to return 0.\n",
      "TorchScript scripting failed, falling back to tracing (dummy forward).\n",
      "Error: Compiled functions can't take variable number of arguments or use keyword-only arguments with defaults:\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/lavis/models/eva_vit.py\", line 198\n",
      "    def forward(self, x, **kwargs):\n",
      "                          ~~~~~~~ <--- HERE\n",
      "        B, C, H, W = x.shape\n",
      "        # FIXME look at relaxing size constraints\n",
      "\n",
      "Model successfully converted via torch.jit.trace (dummy forward).\n",
      "Converted (scripted) model saved locally to: /tmp/blip_ft_production_scripted.pt\n"
     ]
    }
   ],
   "source": [
    "local_converted_path = \"/tmp/blip_ft_production_scripted.pt\"\n",
    "\n",
    "# Set the base model to evaluation mode.\n",
    "base_model.eval()\n",
    "\n",
    "# First wrapper: calls generate (ignored by TorchScript).\n",
    "class BLIPWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(BLIPWrapper, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    @torch.jit.ignore  # This method is ignored during scripting.\n",
    "    def forward(self, image: torch.Tensor):\n",
    "        sample = {\"image\": image, \"text_input\": \"\"}\n",
    "        return self.model.generate(sample)\n",
    "\n",
    "# Second wrapper: defines a TorchScript-friendly forward that calls the visual encoder.\n",
    "class TorchScriptWrapper(torch.nn.Module):\n",
    "    def __init__(self, wrapped_model: BLIPWrapper):\n",
    "        super(TorchScriptWrapper, self).__init__()\n",
    "        self.wrapped_model = wrapped_model\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        # Instead of accessing a non-existent 'vision_encoder',\n",
    "        # we use 'visual_encoder', which should be present on the model.\n",
    "        return self.wrapped_model.model.visual_encoder(image)\n",
    "\n",
    "# Wrap the base model.\n",
    "blip_wrapper = BLIPWrapper(base_model).to(device)\n",
    "ts_wrapper = TorchScriptWrapper(blip_wrapper).to(device)\n",
    "\n",
    "# Monkey-patch torch.distributed.get_rank if the distributed process group is not initialized.\n",
    "import torch.distributed as dist\n",
    "if not dist.is_initialized():\n",
    "    print(\"Distributed process group not initialized; monkey-patching dist.get_rank to return 0.\")\n",
    "    dist.get_rank = lambda: 0\n",
    "\n",
    "try:\n",
    "    # Attempt to script the TorchScript-friendly wrapper.\n",
    "    scripted_model = torch.jit.script(ts_wrapper)\n",
    "    print(\"Model successfully converted via torch.jit.script (dummy forward).\")\n",
    "except Exception as e:\n",
    "    print(\"TorchScript scripting failed, falling back to tracing (dummy forward).\")\n",
    "    print(\"Error:\", e)\n",
    "    dummy_image = torch.randn(1, 3, 224, 224).to(device)\n",
    "    scripted_model = torch.jit.trace(ts_wrapper, dummy_image)\n",
    "    print(\"Model successfully converted via torch.jit.trace (dummy forward).\")\n",
    "\n",
    "scripted_model.save(local_converted_path)\n",
    "print(\"Converted (scripted) model saved locally to:\", local_converted_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2007bdc5-de0a-4c98-bb16-36e2d6ab2dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bentoml\n",
      "  Downloading bentoml-1.4.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting a2wsgi>=1.10.7 (from bentoml)\n",
      "  Downloading a2wsgi-1.10.8-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting aiohttp (from bentoml)\n",
      "  Downloading aiohttp-3.11.13-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting aiosqlite>=0.20.0 (from bentoml)\n",
      "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.11/site-packages (from bentoml) (24.2.0)\n",
      "Collecting cattrs<23.2.0,>=22.1.0 (from bentoml)\n",
      "  Downloading cattrs-23.1.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting click-option-group (from bentoml)\n",
      "  Downloading click_option_group-0.5.6-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.11/site-packages (from bentoml) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from bentoml) (2.2.1)\n",
      "Collecting fs (from bentoml)\n",
      "  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: httpx in /opt/conda/lib/python3.11/site-packages (from bentoml) (0.27.2)\n",
      "Collecting httpx-ws>=0.6.0 (from bentoml)\n",
      "  Downloading httpx_ws-0.7.1-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: jinja2>=3.0.1 in /opt/conda/lib/python3.11/site-packages (from bentoml) (3.1.4)\n",
      "Collecting kantoku>=0.18.1 (from bentoml)\n",
      "  Downloading kantoku-0.18.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from bentoml) (1.26.4)\n",
      "Collecting nvidia-ml-py (from bentoml)\n",
      "  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: opentelemetry-api~=1.20 in /opt/conda/lib/python3.11/site-packages (from bentoml) (1.28.0)\n",
      "Collecting opentelemetry-instrumentation-aiohttp-client~=0.41b0 (from bentoml)\n",
      "  Downloading opentelemetry_instrumentation_aiohttp_client-0.51b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi~=0.41b0 (from bentoml)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation~=0.41b0 (from bentoml)\n",
      "  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk~=1.20 in /opt/conda/lib/python3.11/site-packages (from bentoml) (1.28.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions~=0.41b0 in /opt/conda/lib/python3.11/site-packages (from bentoml) (0.49b0)\n",
      "Collecting opentelemetry-util-http~=0.41b0 (from bentoml)\n",
      "  Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: packaging>=22.0 in /opt/conda/lib/python3.11/site-packages (from bentoml) (24.1)\n",
      "Collecting pathspec (from bentoml)\n",
      "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting pip-requirements-parser>=31.2.0 (from bentoml)\n",
      "  Downloading pip_requirements_parser-32.0.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: prometheus-client>=0.10.0 in /opt/conda/lib/python3.11/site-packages (from bentoml) (0.21.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from bentoml) (6.1.0)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.11/site-packages (from bentoml) (2.9.2)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.11/site-packages (from bentoml) (2.9.0)\n",
      "Requirement already satisfied: python-dotenv>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from bentoml) (1.0.1)\n",
      "Requirement already satisfied: python-json-logger in /opt/conda/lib/python3.11/site-packages (from bentoml) (2.0.7)\n",
      "Collecting python-multipart (from bentoml)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml>=5.0 in /opt/conda/lib/python3.11/site-packages (from bentoml) (6.0.2)\n",
      "Collecting questionary>=2.0.1 (from bentoml)\n",
      "  Downloading questionary-2.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting rich>=11.2.0 (from bentoml)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting schema (from bentoml)\n",
      "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
      "Collecting simple-di>=0.1.4 (from bentoml)\n",
      "  Downloading simple_di-0.1.5-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: starlette>=0.24.0 in /opt/conda/lib/python3.11/site-packages (from bentoml) (0.41.2)\n",
      "Collecting tomli-w (from bentoml)\n",
      "  Downloading tomli_w-1.2.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: uvicorn>=0.22.0 in /opt/conda/lib/python3.11/site-packages (from bentoml) (0.32.0)\n",
      "Requirement already satisfied: watchfiles>=0.15.0 in /opt/conda/lib/python3.11/site-packages (from bentoml) (0.24.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /opt/conda/lib/python3.11/site-packages (from aiosqlite>=0.20.0->bentoml) (4.12.2)\n",
      "Requirement already satisfied: anyio>=4 in /opt/conda/lib/python3.11/site-packages (from httpx-ws>=0.6.0->bentoml) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore>=1.0.4 in /opt/conda/lib/python3.11/site-packages (from httpx-ws>=0.6.0->bentoml) (1.0.6)\n",
      "Collecting wsproto (from httpx-ws>=0.6.0->bentoml)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx->bentoml) (2024.8.30)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.11/site-packages (from httpx->bentoml) (3.10)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from httpx->bentoml) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore>=1.0.4->httpx-ws>=0.6.0->bentoml) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2>=3.0.1->bentoml) (3.0.2)\n",
      "Requirement already satisfied: pyzmq>=17.0 in /opt/conda/lib/python3.11/site-packages (from kantoku>=0.18.1->bentoml) (26.2.0)\n",
      "Requirement already satisfied: tornado>=5.0.2 in /opt/conda/lib/python3.11/site-packages (from kantoku>=0.18.1->bentoml) (6.4.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.11/site-packages (from opentelemetry-api~=1.20->bentoml) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /opt/conda/lib/python3.11/site-packages (from opentelemetry-api~=1.20->bentoml) (8.5.0)\n",
      "Collecting opentelemetry-semantic-conventions~=0.41b0 (from bentoml)\n",
      "  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from opentelemetry-instrumentation~=0.41b0->bentoml) (1.16.0)\n",
      "Collecting opentelemetry-api~=1.20 (from bentoml)\n",
      "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi~=0.41b0->bentoml)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "INFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-sdk~=1.20 (from bentoml)\n",
      "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.11/site-packages (from pip-requirements-parser>=31.2.0->bentoml) (3.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3->bentoml) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.11/site-packages (from pydantic<3->bentoml) (2.23.4)\n",
      "Requirement already satisfied: prompt_toolkit<4.0,>=2.0 in /opt/conda/lib/python3.11/site-packages (from questionary>=2.0.1->bentoml) (3.0.48)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.2.0->bentoml)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=11.2.0->bentoml) (2.18.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->bentoml)\n",
      "  Downloading aiohappyeyeballs-2.4.8-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->bentoml)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->bentoml)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->bentoml)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->bentoml)\n",
      "  Downloading propcache-0.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->bentoml)\n",
      "  Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Collecting appdirs~=1.4.3 (from fs->bentoml)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from fs->bentoml) (75.3.0)\n",
      "Requirement already satisfied: six~=1.10 in /opt/conda/lib/python3.11/site-packages (from fs->bentoml) (1.16.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api~=1.20->bentoml) (3.20.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.2.0->bentoml)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt_toolkit<4.0,>=2.0->questionary>=2.0.1->bentoml) (0.2.13)\n",
      "Downloading bentoml-1.4.2-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading a2wsgi-1.10.8-py3-none-any.whl (17 kB)\n",
      "Downloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
      "Downloading cattrs-23.1.2-py3-none-any.whl (50 kB)\n",
      "Downloading httpx_ws-0.7.1-py3-none-any.whl (14 kB)\n",
      "Downloading kantoku-0.18.1-py3-none-any.whl (118 kB)\n",
      "Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl (30 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
      "Downloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
      "Downloading opentelemetry_instrumentation_aiohttp_client-0.51b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl (7.3 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
      "Downloading pip_requirements_parser-32.0.1-py3-none-any.whl (35 kB)\n",
      "Downloading questionary-2.1.0-py3-none-any.whl (36 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading simple_di-0.1.5-py3-none-any.whl (9.8 kB)\n",
      "Downloading aiohttp-3.11.13-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click_option_group-0.5.6-py3-none-any.whl (12 kB)\n",
      "Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
      "Downloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\n",
      "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
      "Downloading tomli_w-1.2.0-py3-none-any.whl (6.7 kB)\n",
      "Downloading aiohappyeyeballs-2.4.8-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Downloading propcache-0.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
      "Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: schema, nvidia-ml-py, appdirs, wsproto, tomli-w, simple-di, python-multipart, propcache, pip-requirements-parser, pathspec, opentelemetry-util-http, multidict, mdurl, kantoku, fs, frozenlist, click-option-group, cattrs, asgiref, aiosqlite, aiohappyeyeballs, a2wsgi, yarl, questionary, opentelemetry-api, markdown-it-py, aiosignal, rich, opentelemetry-semantic-conventions, httpx-ws, aiohttp, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-aiohttp-client, bentoml\n",
      "  Attempting uninstall: opentelemetry-api\n",
      "    Found existing installation: opentelemetry-api 1.28.0\n",
      "    Uninstalling opentelemetry-api-1.28.0:\n",
      "      Successfully uninstalled opentelemetry-api-1.28.0\n",
      "  Attempting uninstall: opentelemetry-semantic-conventions\n",
      "    Found existing installation: opentelemetry-semantic-conventions 0.49b0\n",
      "    Uninstalling opentelemetry-semantic-conventions-0.49b0:\n",
      "      Successfully uninstalled opentelemetry-semantic-conventions-0.49b0\n",
      "  Attempting uninstall: opentelemetry-sdk\n",
      "    Found existing installation: opentelemetry-sdk 1.28.0\n",
      "    Uninstalling opentelemetry-sdk-1.28.0:\n",
      "      Successfully uninstalled opentelemetry-sdk-1.28.0\n",
      "Successfully installed a2wsgi-1.10.8 aiohappyeyeballs-2.4.8 aiohttp-3.11.13 aiosignal-1.3.2 aiosqlite-0.21.0 appdirs-1.4.4 asgiref-3.8.1 bentoml-1.4.2 cattrs-23.1.2 click-option-group-0.5.6 frozenlist-1.5.0 fs-2.4.16 httpx-ws-0.7.1 kantoku-0.18.1 markdown-it-py-3.0.0 mdurl-0.1.2 multidict-6.1.0 nvidia-ml-py-12.570.86 opentelemetry-api-1.30.0 opentelemetry-instrumentation-0.51b0 opentelemetry-instrumentation-aiohttp-client-0.51b0 opentelemetry-instrumentation-asgi-0.51b0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 opentelemetry-util-http-0.51b0 pathspec-0.12.1 pip-requirements-parser-32.0.1 propcache-0.3.0 python-multipart-0.0.20 questionary-2.1.0 rich-13.9.4 schema-0.7.7 simple-di-0.1.5 tomli-w-1.2.0 wsproto-1.2.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install bentoml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "774217d3-1abc-4938-8033-1a713055b0df",
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingDependencyException",
     "evalue": "'torch' is required in order to use module 'bentoml.pytorch', 'bentoml.torchscript' or 'bentoml.pytorch_lightning'. Install torch with 'pip install torch'. For more information, refer to https://pytorch.org/get-started/locally/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/bentoml/_internal/frameworks/common/pytorch.py:25\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMissingDependencyException\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbentoml\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mbentoml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpytorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblip2-feature-extractor\u001b[39m\u001b[38;5;124m\"\u001b[39m, scripted_model)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/bentoml/_internal/utils/lazy_loader.py:71\u001b[0m, in \u001b[0;36mLazyLoader.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_module, item)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/bentoml/_internal/utils/lazy_loader.py:50\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_module_globals[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_name] \u001b[38;5;241m=\u001b[39m module\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# The additional add to sys.modules ensures library is actually loaded.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/bentoml/_internal/frameworks/pytorch.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyType\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpkg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_pkg_version\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PyTorchTensorContainer\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m torch\n\u001b[1;32m     24\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_model\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_model\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_runnable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyTorchTensorContainer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/bentoml/_internal/frameworks/common/pytorch.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingDependencyException(\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is required in order to use module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbentoml.pytorch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbentoml.torchscript\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbentoml.pytorch_lightning\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Install torch with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install torch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. For more information, refer to https://pytorch.org/get-started/locally/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m     )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n",
      "\u001b[0;31mMissingDependencyException\u001b[0m: 'torch' is required in order to use module 'bentoml.pytorch', 'bentoml.torchscript' or 'bentoml.pytorch_lightning'. Install torch with 'pip install torch'. For more information, refer to https://pytorch.org/get-started/locally/"
     ]
    }
   ],
   "source": [
    "import bentoml\n",
    "bentoml.pytorch.save_model(\"blip2-feature-extractor\", scripted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6501c9a0",
   "metadata": {},
   "source": [
    "## Step 4: Register/Update the MLflow Model \"blip_ft_production\"\n",
    "\n",
    "We log the TorchScript model to the MLflow Model Registry. If the model already exists, a new version is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf93f3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/05 01:28:33 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpynzziyrk/model/data, flavor: pytorch). Fall back to return ['torch==2.6.0', 'cloudpickle==2.2.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/03/05 01:28:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'blip_ft_production' already exists. Creating a new version of this model...\n",
      "2025/03/05 01:30:30 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: blip_ft_production, version 2\n",
      "Created version '2' of model 'blip_ft_production'.\n",
      "2025/03/05 01:30:30 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run unique-dog-358 at: http://mlflow.mlflow.svc.cluster.local:5000/#/experiments/0/runs/861da3c8515b49e096e4093218981c5b.\n",
      "2025/03/05 01:30:30 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://mlflow.mlflow.svc.cluster.local:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged model URI: s3://mlflow.fr2pcai169/0/861da3c8515b49e096e4093218981c5b/artifacts/model\n",
      "Registered model 'blip_ft_production': blip_ft_production\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.pytorch.log_model(\n",
    "        scripted_model,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=\"blip_ft_production\"\n",
    "    )\n",
    "    logged_model_uri = mlflow.get_artifact_uri(\"model\")\n",
    "    print(\"Logged model URI:\", logged_model_uri)\n",
    "\n",
    "# Retrieve the registered model details via the client.\n",
    "client = MlflowClient()\n",
    "registered_model = client.get_registered_model(\"blip_ft_production\")\n",
    "print(\"Registered model 'blip_ft_production':\", registered_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95f4b3d",
   "metadata": {},
   "source": [
    "## Step 5: Generate the KServe InferenceService YAML\n",
    "\n",
    "This YAML configuration points to the MLflow Model Registry so that KServe retrieves the model from the registry (assuming the model version has been promoted to Production)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0b11b2a-ae4a-4a86-929b-b54b62a5c105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow) (75.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.70.0)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.9.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (3.12.1)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m615.4/615.4 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading keras-3.9.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (408 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 keras-3.9.0 libclang-18.1.1 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.14.1 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "66c12079-590c-4d6f-9fe4-0ced8dd88a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://source-images-service.ezdata-system.svc.cluster.local:30000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "\n",
    "object_storage_service_name = \"source-images-service\"\n",
    "object_storage_namespace = \".ezdata-system\"\n",
    "resource_type = \".svc\"\n",
    "domain = \".cluster.local\"\n",
    "object_storage_port = \"30000\"\n",
    "\n",
    "\n",
    "s3_endpoint_url = f\"http://{object_storage_service_name}{object_storage_namespace}{resource_type}{domain}:{object_storage_port}\"\n",
    "print(s3_endpoint_url)\n",
    "\n",
    "\n",
    "s3_client = boto3.client('s3', endpoint_url=s3_endpoint_url)\n",
    "s3_resource = boto3.resource('s3', endpoint_url=s3_endpoint_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32c81d5b-295a-4aa2-8de8-db9ceafc3c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = s3_resource.Bucket('poc-mercedes-gp')\n",
    "\n",
    "training_list = []\n",
    "for bucket_object in bucket.objects.all():\n",
    "    if bucket_object.key.startswith('training/'):\n",
    "        training_list.append(bucket_object.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eaad93bb-b906-43b7-90ca-062746d93af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "bucket_name = \"poc-mercedes-gp\"\n",
    "file_key = \"training/training_dataset.json\"\n",
    "\n",
    "response = s3_client.get_object(Bucket=bucket_name, Key=file_key)\n",
    "content = response[\"Body\"].read().decode(\"utf-8\")  # Convert to string if it's a text file\n",
    "\n",
    "dataset = json.loads(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2514acd-6b58-48b7-820c-ae8e22534d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s3_key': 'training/03_05Bah_Sunday_Alfa Romeo_013.JPG',\n",
       " 'text': 'A photo of a floor'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cebc941-8140-4488-a8c4-d97d4dd2e33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token successfully refreshed.\n",
      "Using logged_model_uri: s3://mlflow.fr2pcai169/0/861da3c8515b49e096e4093218981c5b/artifacts/model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891ce99cffa944dfa9418d71306bc10c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection pool is full, discarding connection: local-s3-service.ezdata-system.svc.cluster.local. Connection pool size: 10\n",
      "Connection pool is full, discarding connection: local-s3-service.ezdata-system.svc.cluster.local. Connection pool size: 10\n",
      "Connection pool is full, discarding connection: local-s3-service.ezdata-system.svc.cluster.local. Connection pool size: 10\n",
      "/opt/conda/lib/python3.11/site-packages/torch/serialization.py:1434: UserWarning: 'torch.load' received a zip file that looks like a TorchScript archive dispatching to 'torch.jit.load' (call 'torch.jit.load' directly to silence this warning)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "%update_token\n",
    "import mlflow.pyfunc\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Assume that 'logged_model_uri' is defined from a previous cell (e.g., obtained via mlflow.get_artifact_uri(\"model\"))\n",
    "print(\"Using logged_model_uri:\", logged_model_uri)\n",
    "\n",
    "# Load the MLflow model using the logged model URI\n",
    "model = mlflow.pyfunc.load_model(logged_model_uri)\n",
    "print(\"Loaded MLflow model from\", logged_model_uri)\n",
    "\n",
    "# Grab the first image's S3 key from the dataset\n",
    "first_image_key = dataset[0]['s3_key']\n",
    "print(\"First image key:\", first_image_key)\n",
    "\n",
    "# Download the image from S3\n",
    "img_response = s3_client.get_object(Bucket=bucket_name, Key=first_image_key)\n",
    "img_data = img_response[\"Body\"].read()\n",
    "\n",
    "# Load and preprocess the image:\n",
    "# - Open with PIL and convert to RGB\n",
    "# - Resize to the expected dimensions (224x224 in this example)\n",
    "# - Convert the image to a NumPy array and add a batch dimension\n",
    "img = Image.open(BytesIO(img_data)).convert(\"RGB\")\n",
    "img_resized = img.resize((224, 224))\n",
    "img_array = np.array(img_resized)\n",
    "img_batch = np.expand_dims(img_array, axis=0)  # shape: [1, 224, 224, 3]\n",
    "\n",
    "# If needed, additional preprocessing (e.g., normalization) can be added here.\n",
    "\n",
    "# Run inference using the loaded MLflow model\n",
    "predictions = model.predict(img_batch)\n",
    "print(\"Inference result:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3341731e-f975-442a-8dec-bd131536ed7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First image key: training/03_05Bah_Sunday_Alfa Romeo_013.JPG\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception when calling CustomObjectsApi->get_namespaced_custom_object:                        (403)\nReason: Forbidden\nHTTP response headers: HTTPHeaderDict({'Audit-Id': '38d18d97-b1c1-42b0-843a-a34791f890b2', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'X-Content-Type-Options': 'nosniff', 'X-Kubernetes-Pf-Flowschema-Uid': 'ba652285-1020-45ae-bed7-4179bed7d5b6', 'X-Kubernetes-Pf-Prioritylevel-Uid': 'aeca4638-6d5f-4da2-a6f6-d553dce60cbf', 'Date': 'Wed, 05 Mar 2025 01:50:10 GMT', 'Content-Length': '458'})\nHTTP response body: {\"kind\":\"Status\",\"apiVersion\":\"v1\",\"metadata\":{},\"status\":\"Failure\",\"message\":\"inferenceservices.serving.kserve.io \\\"blip-ft-production\\\" is forbidden: User \\\"system:serviceaccount:aollman-hpe-com-73b5f55d:default-editor\\\" cannot get resource \\\"inferenceservices\\\" in API group \\\"serving.kserve.io\\\" in the namespace \\\"default\\\"\",\"reason\":\"Forbidden\",\"details\":{\"name\":\"blip-ft-production\",\"group\":\"serving.kserve.io\",\"kind\":\"inferenceservices\"},\"code\":403}\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mApiException\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/kserve/api/kserve_client.py:191\u001b[0m, in \u001b[0;36mKServeClient.get\u001b[0;34m(self, name, namespace, watch, timeout_seconds, version)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_namespaced_custom_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconstants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKSERVE_GROUP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconstants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKSERVE_PLURAL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m client\u001b[38;5;241m.\u001b[39mrest\u001b[38;5;241m.\u001b[39mApiException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/kubernetes/client/api/custom_objects_api.py:1607\u001b[0m, in \u001b[0;36mCustomObjectsApi.get_namespaced_custom_object\u001b[0;34m(self, group, version, namespace, plural, name, **kwargs)\u001b[0m\n\u001b[1;32m   1606\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_return_http_data_only\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_namespaced_custom_object_with_http_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplural\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/kubernetes/client/api/custom_objects_api.py:1714\u001b[0m, in \u001b[0;36mCustomObjectsApi.get_namespaced_custom_object_with_http_info\u001b[0;34m(self, group, version, namespace, plural, name, **kwargs)\u001b[0m\n\u001b[1;32m   1712\u001b[0m auth_settings \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBearerToken\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m-> 1714\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/apis/\u001b[39;49m\u001b[38;5;132;43;01m{group}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{version}\u001b[39;49;00m\u001b[38;5;124;43m/namespaces/\u001b[39;49m\u001b[38;5;132;43;01m{namespace}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{plural}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{name}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mform_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_var_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mobject\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# noqa: E501\u001b[39;49;00m\n\u001b[1;32m   1723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_var_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43masync_req\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_var_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_return_http_data_only\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# noqa: E501\u001b[39;49;00m\n\u001b[1;32m   1726\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_var_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_preload_content\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_var_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_request_timeout\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_formats\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/kubernetes/client/api_client.py:348\u001b[0m, in \u001b[0;36mApiClient.call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m async_req:\n\u001b[0;32m--> 348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__call_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_host\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mapply_async(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_api, (resource_path,\n\u001b[1;32m    356\u001b[0m                                                method, path_params,\n\u001b[1;32m    357\u001b[0m                                                query_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                                _request_timeout,\n\u001b[1;32m    366\u001b[0m                                                _host))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/kubernetes/client/api_client.py:180\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# perform request and return response\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m response_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_response \u001b[38;5;241m=\u001b[39m response_data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/kubernetes/client/api_client.py:373\u001b[0m, in \u001b[0;36mApiClient.request\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrest_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m                                \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m                                \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/kubernetes/client/rest.py:241\u001b[0m, in \u001b[0;36mRESTClientObject.GET\u001b[0;34m(self, url, headers, query_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mGET\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, query_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, _preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    240\u001b[0m         _request_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/kubernetes/client/rest.py:235\u001b[0m, in \u001b[0;36mRESTClientObject.request\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m299\u001b[39m:\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ApiException(http_resp\u001b[38;5;241m=\u001b[39mr)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[0;31mApiException\u001b[0m: (403)\nReason: Forbidden\nHTTP response headers: HTTPHeaderDict({'Audit-Id': '38d18d97-b1c1-42b0-843a-a34791f890b2', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'X-Content-Type-Options': 'nosniff', 'X-Kubernetes-Pf-Flowschema-Uid': 'ba652285-1020-45ae-bed7-4179bed7d5b6', 'X-Kubernetes-Pf-Prioritylevel-Uid': 'aeca4638-6d5f-4da2-a6f6-d553dce60cbf', 'Date': 'Wed, 05 Mar 2025 01:50:10 GMT', 'Content-Length': '458'})\nHTTP response body: {\"kind\":\"Status\",\"apiVersion\":\"v1\",\"metadata\":{},\"status\":\"Failure\",\"message\":\"inferenceservices.serving.kserve.io \\\"blip-ft-production\\\" is forbidden: User \\\"system:serviceaccount:aollman-hpe-com-73b5f55d:default-editor\\\" cannot get resource \\\"inferenceservices\\\" in API group \\\"serving.kserve.io\\\" in the namespace \\\"default\\\"\",\"reason\":\"Forbidden\",\"details\":{\"name\":\"blip-ft-production\",\"group\":\"serving.kserve.io\",\"kind\":\"inferenceservices\"},\"code\":403}\n\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m service_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblip-ft-production\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# update to your deployed service name\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Get the InferenceService details (returns a dict)\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m isvc \u001b[38;5;241m=\u001b[39m \u001b[43mkserve_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mservice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m url \u001b[38;5;241m=\u001b[39m isvc\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m url:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/kserve/api/kserve_client.py:199\u001b[0m, in \u001b[0;36mKServeClient.get\u001b[0;34m(self, name, namespace, watch, timeout_seconds, version)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_instance\u001b[38;5;241m.\u001b[39mget_namespaced_custom_object(\n\u001b[1;32m    192\u001b[0m                 constants\u001b[38;5;241m.\u001b[39mKSERVE_GROUP,\n\u001b[1;32m    193\u001b[0m                 version,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 name,\n\u001b[1;32m    197\u001b[0m             )\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m client\u001b[38;5;241m.\u001b[39mrest\u001b[38;5;241m.\u001b[39mApiException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 199\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    200\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException when calling CustomObjectsApi->get_namespaced_custom_object:\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124m                \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m                 \u001b[38;5;241m%\u001b[39m e\n\u001b[1;32m    203\u001b[0m             )\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m watch:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Exception when calling CustomObjectsApi->get_namespaced_custom_object:                        (403)\nReason: Forbidden\nHTTP response headers: HTTPHeaderDict({'Audit-Id': '38d18d97-b1c1-42b0-843a-a34791f890b2', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'X-Content-Type-Options': 'nosniff', 'X-Kubernetes-Pf-Flowschema-Uid': 'ba652285-1020-45ae-bed7-4179bed7d5b6', 'X-Kubernetes-Pf-Prioritylevel-Uid': 'aeca4638-6d5f-4da2-a6f6-d553dce60cbf', 'Date': 'Wed, 05 Mar 2025 01:50:10 GMT', 'Content-Length': '458'})\nHTTP response body: {\"kind\":\"Status\",\"apiVersion\":\"v1\",\"metadata\":{},\"status\":\"Failure\",\"message\":\"inferenceservices.serving.kserve.io \\\"blip-ft-production\\\" is forbidden: User \\\"system:serviceaccount:aollman-hpe-com-73b5f55d:default-editor\\\" cannot get resource \\\"inferenceservices\\\" in API group \\\"serving.kserve.io\\\" in the namespace \\\"default\\\"\",\"reason\":\"Forbidden\",\"details\":{\"name\":\"blip-ft-production\",\"group\":\"serving.kserve.io\",\"kind\":\"inferenceservices\"},\"code\":403}\n\n\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from kserve import KServeClient\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Grab the first image's S3 key from the dataset\n",
    "first_image_key = dataset[0]['s3_key']\n",
    "print(\"First image key:\", first_image_key)\n",
    "\n",
    "# Download the image from S3\n",
    "img_response = s3_client.get_object(Bucket=bucket_name, Key=first_image_key)\n",
    "img_data = img_response[\"Body\"].read()\n",
    "\n",
    "# Load the image using PIL and convert to RGB\n",
    "img = Image.open(BytesIO(img_data)).convert(\"RGB\")\n",
    "\n",
    "# Preprocess the image: resize to 224x224 and convert to numpy array\n",
    "img_resized = img.resize((224, 224))\n",
    "img_array = np.array(img_resized)\n",
    "\n",
    "# Expand dimensions to create a batch: shape becomes [1, 224, 224, 3]\n",
    "img_batch = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2. Construct the inference payload (V2 protocol)\n",
    "# -----------------------------\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        {\n",
    "            \"name\": \"input\",\n",
    "            \"shape\": list(img_batch.shape),  # e.g., [1, 224, 224, 3]\n",
    "            \"datatype\": \"UINT8\",             # adjust if necessary\n",
    "            \"data\": img_batch.tolist()\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3. Get the InferenceService URL using the KServe Python SDK\n",
    "# -----------------------------\n",
    "kserve_client = KServeClient()\n",
    "namespace = \"default\"                # update if your service is in another namespace\n",
    "service_name = \"blip-ft-production\"  # update to your deployed service name\n",
    "\n",
    "# Get the InferenceService details (returns a dict)\n",
    "isvc = kserve_client.get(service_name, namespace=namespace)\n",
    "url = isvc.get(\"status\", {}).get(\"url\", None)\n",
    "if not url:\n",
    "    raise ValueError(\"Failed to get InferenceService URL.\")\n",
    "print(\"InferenceService URL:\", url)\n",
    "\n",
    "# For V2, the inference endpoint is typically at /v2/models/<service_name>/infer.\n",
    "# Here we assume the service name in the URL is the same as our InferenceService name.\n",
    "infer_url = url.rstrip(\"/\") + f\"/v2/models/{service_name}/infer\"\n",
    "print(\"Inference endpoint:\", infer_url)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 4. Send the inference request\n",
    "# -----------------------------\n",
    "response = requests.post(infer_url, json=payload)\n",
    "print(\"Inference response:\")\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f2d68d",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Deploy the Model via KServe:**  \n",
    "   Apply the generated YAML to your Kubernetes cluster:\n",
    "   ```bash\n",
    "   kubectl apply -f inference_service_mlflow.yaml\n",
    "   ```\n",
    "\n",
    "2. **Verify the Deployment:**  \n",
    "   Ensure the InferenceService is running and your custom predictor (if needed) is correctly loading the model from MLflow.\n",
    "\n",
    "3. **Inference:**  \n",
    "   Once deployed, use the KServe endpoint to send inference requests to your model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
